# Paging
Paging no longer looks at processes as one big chunk of contiguous memory. We divide a processes' memory into chunks of the same size, called *pages*.

To contain pages, we partition memory into equal, fixed-size chunks called *page frames* or *frames*. To simplify translation, page frame sizes are powers of 2.

To store a process divided into N pages, we will need N available page frames, that dont necessarily have to be contiguous!

![paging](paging.png)

Pages up to N-1 are all filled, and only the last page may be non-full. This means internal fragmentation is isolated to at most one page per process. As well, no external fragmentation occurs.

## Caching
The page table for a process is stored in memory. This means, however, that to find the physical address, we have to access memory to get the page table, and that tells us where the physical address is. For each call, we are doubling the number of memory accesses we need.

To solve this issue, we use a hardware cache for page table entries, called the **Translation Lookaside Buffer (TLB)**. If we can find the pte in the tlb, then we can go directly to the physical address (TLB hit). If we don't find the pte, then we lookup the page table as we normally would (TLB miss).

![translate-lookaside-buf.png](translate-lookaside-buf.png)

TLBs implemented in hardware are a lot closer to the CPU than main memory, so it is a lot faster to access and check than accessing the page table. They are  fully associative, so all entries are looked up in parallel.

Each cache entry is a cache tag and a cache value:
* Cache tags are virtual page numbers
* Cache values are PTEs (entries from page tables)
* With PTE + offset, we can directly calculate physical address

TLBs are small, containing 64-1024 entries. However, most of the translations are handled by the TLB (>99% of them!).

Processes only use a handful of pages at a time. A game wouldn't load into memory all of graphics it has, but only graphics related to the current level or map. Since only a handful of pages are used at a time by a process, TLBs exploit this to increase the hit rate of address translations.

While hardware TLBs are fast, tables have to be in the pre-defined format.
> TLBs can also be implemented in software. Advantageously, the format of the TLB table can be changed, and is therefore more flexible.

## Maintaining TLBs
For hardware TLBs, entries are loaded by the Memory Management Unit (MMU).

Software TLBs are maintained by the OS. It finds the PTE, and loads it in the TLB (must be fast, within 20-200 CPU cycles). To do so, the CPU may provide an instruction 'IS A' for manipulating the TLB.

The TLB and page tables need to be consistent with each other, and it is the OS's job to do so.

We will need certain policies to enact if either the cache or main memory is full. We choose one PTE to evict in either case in order to accomodate the new PTE:
* **TLB Replacement Policy** - which PTE to evict from cache
* **Fetch policy** - when to fetch a page
* **Placement policy** - where to put the page
* **Replacement policy** - what page to evict to make room?

During a process context switch, we need to invalidate all entries in the cache. This is a security concern, as a new process might snoop on the previous process' memory and/or activity otherwise.

Additionally, if a process is evicted from main memory, we move the entry to swap space and also need to invalidate the cache entry. The page table entry stores the disk location instead.

## Multi-level Page Tables
In paging, we can have a 16, 32, or even 64-bit virtual address. Most commonly, page sizes are 4096 (2^12) bits, which we will use for offset (specific line within the page).

That leaves us with either 4, 20, or 52 bits for page addressing and 16, 1048576, or 4.5035 x 10^15 pages! This is too much space to store the page number of a virtual address.

We can solve this problem by using multi-level page tables. We have three parts
* Master page number - maps virtual address to secondary page table
* Secondary page number - maps page number to physical frame
* Offset - selects address within physical frame

![two-level-page-table](two-level-page-table.png)

## Inverted Page Tables
Instead of storing PTEs for each process, we store one table with an entry for each physical page frame. Each entry records:
* which virtual page # is stored in that frame.
* process id using that frame

Takes less space, but lookups are a lot slower. References use virtual addresses, and table is indexed by physical addresses.

Inverted page table is basically a large hash table, to reduce the search time.

## Linux Paging
* Linux uses global replacement, like most of Unix.
* Replacement policy is a modified second-chance clock algorithm
	* Pages age with each pass of the clock hand
	* Pages not used for a long time eventually have a value of zero
